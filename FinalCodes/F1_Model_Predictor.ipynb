{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "#taking data from ergast via json and also wherever data is not there, we are putting None there\n",
    "\n",
    "#Making dictionary of lists for needful features\n",
    "races = {'season': [],\n",
    "        'round': [],\n",
    "        'circuit_id': [],\n",
    "        'lat': [],\n",
    "        'long': [],\n",
    "        'country': [],\n",
    "        'date': [],\n",
    "        'url': []}\n",
    "\n",
    "#For now we are taking data from 2015 to 2022 season\n",
    "for year in list(range(2015,2023)):\n",
    "    \n",
    "    url = 'https://ergast.com/api/f1/{}.json'\n",
    "    r = requests.get(url.format(year))\n",
    "    json = r.json()\n",
    "\n",
    "    for item in json['MRData']['RaceTable']['Races']:\n",
    "        try:\n",
    "            races['season'].append(int(item['season']))\n",
    "        except:\n",
    "            races['season'].append(None)\n",
    "\n",
    "        try:\n",
    "            races['round'].append(int(item['round']))\n",
    "        except:\n",
    "            races['round'].append(None)\n",
    "\n",
    "        try:\n",
    "            races['circuit_id'].append(item['Circuit']['circuitId'])\n",
    "        except:\n",
    "            races['circuit_id'].append(None)\n",
    "\n",
    "        try:\n",
    "            races['lat'].append(float(item['Circuit']['Location']['lat']))\n",
    "        except:\n",
    "            races['lat'].append(None)\n",
    "\n",
    "        try:\n",
    "            races['long'].append(float(item['Circuit']['Location']['long']))\n",
    "        except:\n",
    "            races['long'].append(None)\n",
    "\n",
    "        try:\n",
    "            races['country'].append(item['Circuit']['Location']['country'])\n",
    "        except:\n",
    "            races['country'].append(None)\n",
    "\n",
    "        try:\n",
    "            races['date'].append(item['date'])\n",
    "        except:\n",
    "            races['date'].append(None)\n",
    "\n",
    "        try:\n",
    "            races['url'].append(item['url'])\n",
    "        except:\n",
    "            races['url'].append(None)\n",
    "        \n",
    "races = pd.DataFrame(races)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an excel of races for data analysis\n",
    "races.to_csv(\"Races2015_2022.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterating through each season to get driver data and winner's data for each race ex. podium data\n",
    "import numpy as np\n",
    "\n",
    "#Making rounds list so that we can iterate later on through it for data fetching for each round\n",
    "rounds = []\n",
    "for year in np.array(races.season.unique()):\n",
    "    rounds.append([year, list(races[races.season == year]['round'])])\n",
    "\n",
    "#Making dictionary of lists for needful features\n",
    "\n",
    "results = {'season': [],\n",
    "          'round':[],\n",
    "           'circuit_id':[],\n",
    "          'driver': [],\n",
    "           'date_of_birth': [],\n",
    "           'nationality': [],\n",
    "          'constructor': [],\n",
    "          'grid': [],\n",
    "          'time': [],\n",
    "          'status': [],\n",
    "          'points': [],\n",
    "          'podium': []}\n",
    "\n",
    "for n in list(range(len(rounds))):\n",
    "    for i in rounds[n][1]:\n",
    "    \n",
    "        url = 'http://ergast.com/api/f1/{}/{}/results.json'\n",
    "        r = requests.get(url.format(rounds[n][0], i))\n",
    "        json = r.json()\n",
    "\n",
    "        for item in json['MRData']['RaceTable']['Races'][0]['Results']:\n",
    "            try:\n",
    "                results['season'].append(int(json['MRData']['RaceTable']['Races'][0]['season']))\n",
    "            except:\n",
    "                results['season'].append(None)\n",
    "\n",
    "            try:\n",
    "                results['round'].append(int(json['MRData']['RaceTable']['Races'][0]['round']))\n",
    "            except:\n",
    "                results['round'].append(None)\n",
    "\n",
    "            try:\n",
    "                results['circuit_id'].append(json['MRData']['RaceTable']['Races'][0]['Circuit']['circuitId'])\n",
    "            except:\n",
    "                results['circuit_id'].append(None)\n",
    "\n",
    "            try:\n",
    "                results['driver'].append(item['Driver']['driverId'])\n",
    "            except:\n",
    "                results['driver'].append(None)\n",
    "            \n",
    "            try:\n",
    "                results['date_of_birth'].append(item['Driver']['dateOfBirth'])\n",
    "            except:\n",
    "                results['date_of_birth'].append(None)\n",
    "                \n",
    "            try:\n",
    "                results['nationality'].append(item['Driver']['nationality'])\n",
    "            except:\n",
    "                results['nationality'].append(None)\n",
    "\n",
    "            try:\n",
    "                results['constructor'].append(item['Constructor']['constructorId'])\n",
    "            except:\n",
    "                results['constructor'].append(None)\n",
    "\n",
    "            try:\n",
    "                results['grid'].append(int(item['grid']))\n",
    "            except:\n",
    "                results['grid'].append(None)\n",
    "\n",
    "            try:\n",
    "                results['time'].append(int(item['Time']['millis']))\n",
    "            except:\n",
    "                results['time'].append(None)\n",
    "\n",
    "            try:\n",
    "                results['status'].append(item['status'])\n",
    "            except:\n",
    "                results['status'].append(None)\n",
    "\n",
    "            try:\n",
    "                results['points'].append(int(item['points']))\n",
    "            except:\n",
    "                results['points'].append(None)\n",
    "\n",
    "            try:\n",
    "                results['podium'].append(int(item['position']))\n",
    "            except:\n",
    "                results['podium'].append(None)\n",
    "\n",
    "           \n",
    "results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an excel of results for data analysis\n",
    "results.to_csv(\"Results2015_2022.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making dictionary of lists for needful features\n",
    "driver_standings = {'season': [],\n",
    "                    'round':[],\n",
    "                    'driver': [],\n",
    "                    'driver_points': [],\n",
    "                    'driver_wins': [],\n",
    "                   'driver_standings_pos': []}\n",
    "\n",
    "#Making driver standings list for each round\n",
    "for n in list(range(len(rounds))):     \n",
    "    for i in rounds[n][1]:    # iterate through rounds of each year\n",
    "    \n",
    "        url = 'https://ergast.com/api/f1/{}/{}/driverStandings.json'\n",
    "        r = requests.get(url.format(rounds[n][0], i))\n",
    "        json = r.json()\n",
    "\n",
    "        for item in json['MRData']['StandingsTable']['StandingsLists'][0]['DriverStandings']:\n",
    "            try:\n",
    "                driver_standings['season'].append(int(json['MRData']['StandingsTable']['StandingsLists'][0]['season']))\n",
    "            except:\n",
    "                driver_standings['season'].append(None)\n",
    "\n",
    "            try:\n",
    "                driver_standings['round'].append(int(json['MRData']['StandingsTable']['StandingsLists'][0]['round']))\n",
    "            except:\n",
    "                driver_standings['round'].append(None)\n",
    "                                         \n",
    "            try:\n",
    "                driver_standings['driver'].append(item['Driver']['driverId'])\n",
    "            except:\n",
    "                driver_standings['driver'].append(None)\n",
    "            \n",
    "            try:\n",
    "                driver_standings['driver_points'].append(int(item['points']))\n",
    "            except:\n",
    "                driver_standings['driver_points'].append(None)\n",
    "            \n",
    "            try:\n",
    "                driver_standings['driver_wins'].append(int(item['wins']))\n",
    "            except:\n",
    "                driver_standings['driver_wins'].append(None)\n",
    "                \n",
    "            try:\n",
    "                driver_standings['driver_standings_pos'].append(int(item['position']))\n",
    "            except:\n",
    "                driver_standings['driver_standings_pos'].append(None)\n",
    "            \n",
    "driver_standings = pd.DataFrame(driver_standings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to create a function which will add up points as points are given after race completion so they needs to be added up in the next race \n",
    "#to shift points and number of wins from previous rounds\n",
    "def lookup (df, team, points):\n",
    "    df['lookup1'] = df.season.astype(str) + df[team] + df['round'].astype(str)\n",
    "    df['lookup2'] = df.season.astype(str) + df[team] + (df['round']-1).astype(str)\n",
    "    new_df = df.merge(df[['lookup1', points]], how = 'left', left_on='lookup2',right_on='lookup1')\n",
    "    new_df.drop(['lookup1_x', 'lookup2', 'lookup1_y'], axis = 1, inplace = True)\n",
    "    new_df.rename(columns = {points+'_x': points+'_after_race', points+'_y': points}, inplace = True)\n",
    "    new_df[points].fillna(0, inplace = True)\n",
    "    return new_df\n",
    "  \n",
    "driver_standings = lookup(driver_standings, 'driver', 'driver_points')\n",
    "driver_standings = lookup(driver_standings, 'driver', 'driver_wins')\n",
    "driver_standings = lookup(driver_standings, 'driver', 'driver_standings_pos')\n",
    "\n",
    "driver_standings.drop(['driver_points_after_race', 'driver_wins_after_race', 'driver_standings_pos_after_race'], \n",
    "                      axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an excel of driver standings for data analysis\n",
    "driver_standings.to_csv(\"Dr_standings2015_2022.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making dictionary of lists for needful features\n",
    "constructor_rounds = rounds[:]\n",
    "constructor_standings = {'season': [],\n",
    "                    'round':[],\n",
    "                    'constructor': [],\n",
    "                    'constructor_points': [],\n",
    "                    'constructor_wins': [],\n",
    "                   'constructor_standings_pos': []}\n",
    "\n",
    "#Making constructor standings list for each round\n",
    "for n in list(range(len(constructor_rounds))):\n",
    "    for i in constructor_rounds[n][1]:\n",
    "    \n",
    "        url = 'https://ergast.com/api/f1/{}/{}/constructorStandings.json'\n",
    "        r = requests.get(url.format(constructor_rounds[n][0], i))\n",
    "        json = r.json()\n",
    "\n",
    "        for item in json['MRData']['StandingsTable']['StandingsLists'][0]['ConstructorStandings']:\n",
    "            try:\n",
    "                constructor_standings['season'].append(int(json['MRData']['StandingsTable']['StandingsLists'][0]['season']))\n",
    "            except:\n",
    "                constructor_standings['season'].append(None)\n",
    "\n",
    "            try:\n",
    "                constructor_standings['round'].append(int(json['MRData']['StandingsTable']['StandingsLists'][0]['round']))\n",
    "            except:\n",
    "                constructor_standings['round'].append(None)\n",
    "                                         \n",
    "            try:\n",
    "                constructor_standings['constructor'].append(item['Constructor']['constructorId'])\n",
    "            except:\n",
    "                constructor_standings['constructor'].append(None)\n",
    "            \n",
    "            try:\n",
    "                constructor_standings['constructor_points'].append(int(item['points']))\n",
    "            except:\n",
    "                constructor_standings['constructor_points'].append(None)\n",
    "            \n",
    "            try:\n",
    "                constructor_standings['constructor_wins'].append(int(item['wins']))\n",
    "            except:\n",
    "                constructor_standings['constructor_wins'].append(None)\n",
    "                \n",
    "            try:\n",
    "                constructor_standings['constructor_standings_pos'].append(int(item['position']))\n",
    "            except:\n",
    "                constructor_standings['constructor_standings_pos'].append(None)\n",
    "            \n",
    "constructor_standings = pd.DataFrame(constructor_standings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying same lookup and logic here as driver stadings\n",
    "constructor_standings = lookup(constructor_standings, 'constructor', 'constructor_points')\n",
    "constructor_standings = lookup(constructor_standings, 'constructor', 'constructor_wins')\n",
    "constructor_standings = lookup(constructor_standings, 'constructor', 'constructor_standings_pos')\n",
    "\n",
    "constructor_standings.drop(['constructor_points_after_race', 'constructor_wins_after_race','constructor_standings_pos_after_race' ],\n",
    "                           axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an excel of driver standings for data analysis\n",
    "constructor_standings.to_csv(\"construct_standings2015_2022.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gathering qualifying results from 2015 to 2022 using beautiful soup via web scrapping\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#creating empty dataframe\n",
    "qualifying_results = pd.DataFrame()\n",
    "\n",
    "for year in list(range(2015,2023)):\n",
    "    url = 'https://www.formula1.com/en/results.html/{}/races.html'\n",
    "    r = requests.get(url.format(year))\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "    year_links = []\n",
    "    #finding all circuits links for each year\n",
    "    for page in soup.find_all('a', attrs = {'class':\"resultsarchive-filter-item-link FilterTrigger\"}):\n",
    "        link = page.get('href')\n",
    "        if f'/en/results.html/{year}/races/' in link: \n",
    "            year_links.append(link)\n",
    "\n",
    "    #creating an empty dataframe\n",
    "    year_df = pd.DataFrame()\n",
    "    new_url = 'https://www.formula1.com{}'\n",
    "    for n, link in list(enumerate(year_links)):\n",
    "        #or each circuit, switching to the starting grid page and reading table from it\n",
    "        link = link.replace('race-result.html', 'starting-grid.html')\n",
    "        df = pd.read_html(new_url.format(link))\n",
    "        df = df[0]\n",
    "        df['season'] = year\n",
    "        df['round'] = n+1\n",
    "        for col in df:\n",
    "            if 'Unnamed' in col:\n",
    "                df.drop(col, axis = 1, inplace = True)\n",
    "        year_df = pd.concat([year_df, df])\n",
    "\n",
    "    # concatenating all tables from all years now\n",
    "    qualifying_results = pd.concat([qualifying_results, year_df])\n",
    "\n",
    "#renaming columns for better understanding\n",
    "qualifying_results.rename(columns = {'Pos': 'grid', 'Driver': 'driver_name', 'Car': 'car',\n",
    "                                     'Time': 'qualifying_time'}, inplace = True)\n",
    "\n",
    "#we don't need driver number here as we have driver name to identify so dropping it\n",
    "qualifying_results.drop('No', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an excel of qualifying results\n",
    "qualifying_results.to_csv(\"Qualifying2015_2022.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     season  round   circuit_id        date   \n",
      "0      2015      1  albert_park  2015-03-15  \\\n",
      "1      2015      2       sepang  2015-03-29   \n",
      "2      2015      3     shanghai  2015-04-12   \n",
      "3      2015      4      bahrain  2015-04-19   \n",
      "4      2015      5    catalunya  2015-05-10   \n",
      "..      ...    ...          ...         ...   \n",
      "158    2022     18       suzuka  2022-10-09   \n",
      "159    2022     19     americas  2022-10-23   \n",
      "160    2022     20    rodriguez  2022-10-30   \n",
      "161    2022     21   interlagos  2022-11-13   \n",
      "162    2022     22   yas_marina  2022-11-20   \n",
      "\n",
      "                                                   url  \n",
      "0    http://en.wikipedia.org/wiki/2015_Australian_G...  \n",
      "1    http://en.wikipedia.org/wiki/2015_Malaysian_Gr...  \n",
      "2    http://en.wikipedia.org/wiki/2015_Chinese_Gran...  \n",
      "3    http://en.wikipedia.org/wiki/2015_Bahrain_Gran...  \n",
      "4    http://en.wikipedia.org/wiki/2015_Spanish_Gran...  \n",
      "..                                                 ...  \n",
      "158  http://en.wikipedia.org/wiki/2022_Japanese_Gra...  \n",
      "159  http://en.wikipedia.org/wiki/2022_United_State...  \n",
      "160  http://en.wikipedia.org/wiki/2022_Mexican_Gran...  \n",
      "161  http://en.wikipedia.org/wiki/2022_Brazilian_Gr...  \n",
      "162  http://en.wikipedia.org/wiki/2022_Abu_Dhabi_Gr...  \n",
      "\n",
      "[163 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#dropping unnecessary columns from races dataframe before merging\n",
    "races.drop(['lat', 'long','country'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging all dataframes to create one final dataframe\n",
    "df1= pd.merge(races, results, how='inner', on=['season', 'round', 'circuit_id']).drop(['url','points', 'status', 'time'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2= pd.merge(df1, driver_standings, how='left', on=['season', 'round', 'driver'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.merge(df2, constructor_standings, how='left', on=['season', 'round', 'constructor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.merge(df3, qualifying_results, how='inner', on=['season', 'round', 'grid']).drop(['driver_name', 'car'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating age of drivers as we will take it as a parameter as it impact health due to g torque.\n",
    "from dateutil.relativedelta import *\n",
    "\n",
    "final_df['date'] = pd.to_datetime(final_df.date)\n",
    "final_df['date_of_birth'] = pd.to_datetime(final_df.date_of_birth)\n",
    "final_df['driver_age'] = final_df.apply(lambda x: relativedelta(x['date'], x['date_of_birth']).years, axis=1)\n",
    "final_df.drop(['date', 'date_of_birth'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling missing values\n",
    "for col in ['driver_points', 'driver_wins', 'driver_standings_pos', 'constructor_points', 'constructor_wins' , 'constructor_standings_pos']:\n",
    "    final_df[col].fillna(0, inplace = True)\n",
    "    final_df[col] = final_df[col].map(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.dropna(inplace = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#calculating difference of qualifying times so we can get how fast one car is from another\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m final_df[\u001b[39m'\u001b[39m\u001b[39mqualifying_time\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m final_df\u001b[39m.\u001b[39;49mqualifying_time\u001b[39m.\u001b[39;49mmap(\u001b[39mlambda\u001b[39;49;00m x: \u001b[39m0\u001b[39;49m \u001b[39mif\u001b[39;49;00m \u001b[39mstr\u001b[39;49m(x) \u001b[39m==\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m00.000\u001b[39;49m\u001b[39m'\u001b[39;49m \n\u001b[0;32m      4\u001b[0m                              \u001b[39melse\u001b[39;49;00m(\u001b[39mfloat\u001b[39;49m(\u001b[39mstr\u001b[39;49m(x)\u001b[39m.\u001b[39;49msplit(\u001b[39m'\u001b[39;49m\u001b[39m:\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m1\u001b[39;49m]) \u001b[39m+\u001b[39;49m \n\u001b[0;32m      5\u001b[0m                                   (\u001b[39m60\u001b[39;49m \u001b[39m*\u001b[39;49m \u001b[39mfloat\u001b[39;49m(\u001b[39mstr\u001b[39;49m(x)\u001b[39m.\u001b[39;49msplit(\u001b[39m'\u001b[39;49m\u001b[39m:\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m0\u001b[39;49m])) \u001b[39mif\u001b[39;49;00m x \u001b[39m!=\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m \u001b[39m0\u001b[39;49m))\n\u001b[0;32m      6\u001b[0m final_df \u001b[39m=\u001b[39m final_df[final_df[\u001b[39m'\u001b[39m\u001b[39mqualifying_time\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m]\n\u001b[0;32m      7\u001b[0m final_df\u001b[39m.\u001b[39msort_values([\u001b[39m'\u001b[39m\u001b[39mseason\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mround\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgrid\u001b[39m\u001b[39m'\u001b[39m], inplace \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mi:\\PythonInstallation\\Lib\\site-packages\\pandas\\core\\series.py:4398\u001b[0m, in \u001b[0;36mSeries.map\u001b[1;34m(self, arg, na_action)\u001b[0m\n\u001b[0;32m   4319\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap\u001b[39m(\n\u001b[0;32m   4320\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4321\u001b[0m     arg: Callable \u001b[39m|\u001b[39m Mapping \u001b[39m|\u001b[39m Series,\n\u001b[0;32m   4322\u001b[0m     na_action: Literal[\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   4323\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series:\n\u001b[0;32m   4324\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4325\u001b[0m \u001b[39m    Map values of Series according to an input mapping or function.\u001b[39;00m\n\u001b[0;32m   4326\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4396\u001b[0m \u001b[39m    dtype: object\u001b[39;00m\n\u001b[0;32m   4397\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4398\u001b[0m     new_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_values(arg, na_action\u001b[39m=\u001b[39;49mna_action)\n\u001b[0;32m   4399\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(new_values, index\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39m__finalize__(\n\u001b[0;32m   4400\u001b[0m         \u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmap\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   4401\u001b[0m     )\n",
      "File \u001b[1;32mi:\\PythonInstallation\\Lib\\site-packages\\pandas\\core\\base.py:924\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action)\u001b[0m\n\u001b[0;32m    921\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m    923\u001b[0m \u001b[39m# mapper is a function\u001b[39;00m\n\u001b[1;32m--> 924\u001b[0m new_values \u001b[39m=\u001b[39m map_f(values, mapper)\n\u001b[0;32m    926\u001b[0m \u001b[39mreturn\u001b[39;00m new_values\n",
      "File \u001b[1;32mi:\\PythonInstallation\\Lib\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[85], line 4\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#calculating difference of qualifying times so we can get how fast one car is from another\u001b[39;00m\n\u001b[0;32m      3\u001b[0m final_df[\u001b[39m'\u001b[39m\u001b[39mqualifying_time\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m final_df\u001b[39m.\u001b[39mqualifying_time\u001b[39m.\u001b[39mmap(\u001b[39mlambda\u001b[39;00m x: \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mstr\u001b[39m(x) \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m00.000\u001b[39m\u001b[39m'\u001b[39m \n\u001b[1;32m----> 4\u001b[0m                              \u001b[39melse\u001b[39;00m(\u001b[39mfloat\u001b[39m(\u001b[39mstr\u001b[39;49m(x)\u001b[39m.\u001b[39;49msplit(\u001b[39m'\u001b[39;49m\u001b[39m:\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m1\u001b[39;49m]) \u001b[39m+\u001b[39m \n\u001b[0;32m      5\u001b[0m                                   (\u001b[39m60\u001b[39m \u001b[39m*\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39mstr\u001b[39m(x)\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m])) \u001b[39mif\u001b[39;00m x \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m))\n\u001b[0;32m      6\u001b[0m final_df \u001b[39m=\u001b[39m final_df[final_df[\u001b[39m'\u001b[39m\u001b[39mqualifying_time\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m]\n\u001b[0;32m      7\u001b[0m final_df\u001b[39m.\u001b[39msort_values([\u001b[39m'\u001b[39m\u001b[39mseason\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mround\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgrid\u001b[39m\u001b[39m'\u001b[39m], inplace \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#calculating difference of qualifying times so we can get how fast one car is from another\n",
    "\n",
    "final_df['qualifying_time'] = final_df.qualifying_time.map(lambda x: 0 if str(x) == '00.000' \n",
    "                             else(float(str(x).split(':')[1]) + \n",
    "                                  (60 * float(str(x).split(':')[0])) if x != 0 else 0))\n",
    "final_df = final_df[final_df['qualifying_time'] != 0]\n",
    "final_df.sort_values(['season', 'round', 'grid'], inplace = True)\n",
    "final_df['qualifying_time_diff'] = final_df.groupby(['season', 'round']).qualifying_time.diff()\n",
    "final_df['qualifying_time'] = final_df.groupby(['season', 'round']).qualifying_time_diff.cumsum().fillna(0)\n",
    "final_df.drop('qualifying_time_diff', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final preprocessed Excel\n",
    "final_df.to_csv(\"Final2015_2022.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
